{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating notebook for: scraping_notebooks/data_avito_page_1_to_500.csv\n",
      "Inspecting code cell: ['import pandas as pd\\n', 'import requests\\n', 'from bs4 import BeautifulSoup\\n', 'from datetime import datetime\\n', 'import os\\n', '\\n', \"data_base_path = '../scraped_data'\\n\", 'os.makedirs(data_base_path, exist_ok=True)\\n', '\\n', 'data = []\\n', 'start_page = 0\\n', 'end_page = 1\\n', '\\n', 'page_number = start_page\\n', 'max_pages = end_page\\n', '\\n', 'prix_min = 1\\n', '\\n', 'headers = {\\n', \"    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\\n\", \"    'Accept-Language': 'en-US,en;q=0.9',\\n\", '}\\n', '\\n', 'equipements_possibles = [\\n', \"    'ABS',\\n\", \"    'Airbags',\\n\", \"    'CD/MP3/Bluetooth',\\n\", \"    'Caméra de recul',\\n\", \"    'Climatisation',\\n\", \"    'ESP',\\n\", \"    'Jantes aluminium',\\n\", \"    'Limiteur de vitesse',\\n\", \"    'Ordinateur de bord',\\n\", \"    'Radar de recul',\\n\", \"    'Régulateur de vitesse',\\n\", \"    'Sièges cuir',\\n\", \"    'Système de navigation/GPS',\\n\", \"    'Toit ouvrant',\\n\", \"    'Verrouillage centralisé à distance',\\n\", \"    'Vitres électriques'\\n\", ']\\n', '\\n', '# while True:\\n', 'while page_number <= max_pages:\\n', '   url = f\"https://www.avito.ma/fr/maroc/voitures_d_occasion-à_vendre?price={prix_min}&o={page_number}\"\\n', '   print(f\"\\\\nPage-{page_number}\", end=\\' \\')\\n', '   page_number += 1\\n', '   response = requests.get(url, headers=headers)\\n', \"   soupe = BeautifulSoup(response.text, 'html.parser')\\n\", \"   cars = soupe.select('a.sc-1jge648-0.jZXrfL')\\n\", \"   links = [car.get('href') for car in cars]\\n\", '\\n', '   if (len(links) == 0):\\n', '      break\\n', '\\n', '   for i, link in enumerate(links):\\n', '      # print(f\"{i}\", end=\\' \\')\\n', '      reponse_voiture = requests.get(link, headers=headers)\\n', \"      soup = BeautifulSoup(reponse_voiture.text, 'html.parser')\\n\", \"      titre = soup.find('h1').text.strip() if soup.find('h1') else ''\\n\", '      localisation = soup.select_one(\\n', \"          'span.sc-1x0vz2r-0').text.strip() if soup.select_one('span.sc-1x0vz2r-0') else ''\\n\", \"      prix = soup.select_one('p.sc-1x0vz2r-0.lnEFFR.sc-1veij0r-10.jdRkSM').text.strip(\\n\", \"      ) if soup.select_one('p.sc-1x0vz2r-0.lnEFFR.sc-1veij0r-10.jdRkSM') else ''\\n\", '\\n', \"      car_details = soup.select('div.sc-19cngu6-1.doRGIC')\\n\", '      car = {\\n', \"          'Titre': titre,\\n\", \"          'Localisation': localisation,\\n\", \"          'Prix': prix,\\n\", \"          'Année-Modèle': '',\\n\", \"          'Boite de vitesses': '',\\n\", \"          'Type de carburant': '',\\n\", \"          'Kilométrage': '',\\n\", \"          'Marque': '',\\n\", \"          'Modèle': '',\\n\", \"          'Nombre de portes': '',\\n\", \"          'Origine': '',\\n\", \"          'Première main': '',\\n\", \"          'Puissance fiscale': '',\\n\", \"          'État': ''\\n\", '      }\\n', '\\n', '      # les détails de la voitures\\n', '      for detail in car_details:\\n', \"         label = detail.select_one('span.sc-1x0vz2r-0.bXFCIH')\\n\", \"         value = detail.select_one('span.sc-1x0vz2r-0.fjZBup')\\n\", '         if label and value:\\n', '            key = label.text.strip()\\n', '            value = value.text.strip()\\n', '            car[key] = value\\n', '\\n', '      # Initialiser tous les équipements à False\\n', '      for eq in equipements_possibles:\\n', '         car[eq] = False\\n', '\\n', \"      # Sélectionner tous les icônes d'équipements\\n\", \"      equip_icons = soup.select('div.sc-19cngu6-1.doRGIC img')\\n\", '      for icon in equip_icons:\\n', \"         alt_text = icon.get('alt', '').strip()\\n\", '         if alt_text in equipements_possibles:\\n', '            car[alt_text] = True\\n', '      data.append(car)\\n', '\\n', '\\n', 'df = pd.DataFrame(data, columns=car.keys())\\n', '\\n', 'timestamp = datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")\\n', 'df.to_csv(\\n', '    f\"{data_base_path}/data_avito_{start_page}_to_{end_page}_pages_{timestamp}.csv\", index=False)']\n",
      "Found start_page in line: start_page = 0\n",
      "\n",
      "Found end_page in line: end_page = 1\n",
      "\n",
      "Created notebook: scraping_notebooks/data_avito_notebook_1_to_500.ipynb\n",
      "Generating notebook for: scraping_notebooks/data_avito_page_501_to_1000.csv\n",
      "Inspecting code cell: ['import pandas as pd\\n', 'import requests\\n', 'from bs4 import BeautifulSoup\\n', 'from datetime import datetime\\n', 'import os\\n', '\\n', \"data_base_path = '../scraped_data'\\n\", 'os.makedirs(data_base_path, exist_ok=True)\\n', '\\n', 'data = []\\n', 'start_page = 1\\n', 'end_page = 500\\n', '\\n', 'page_number = start_page\\n', 'max_pages = end_page\\n', '\\n', 'prix_min = 1\\n', '\\n', 'headers = {\\n', \"    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\\n\", \"    'Accept-Language': 'en-US,en;q=0.9',\\n\", '}\\n', '\\n', 'equipements_possibles = [\\n', \"    'ABS',\\n\", \"    'Airbags',\\n\", \"    'CD/MP3/Bluetooth',\\n\", \"    'Caméra de recul',\\n\", \"    'Climatisation',\\n\", \"    'ESP',\\n\", \"    'Jantes aluminium',\\n\", \"    'Limiteur de vitesse',\\n\", \"    'Ordinateur de bord',\\n\", \"    'Radar de recul',\\n\", \"    'Régulateur de vitesse',\\n\", \"    'Sièges cuir',\\n\", \"    'Système de navigation/GPS',\\n\", \"    'Toit ouvrant',\\n\", \"    'Verrouillage centralisé à distance',\\n\", \"    'Vitres électriques'\\n\", ']\\n', '\\n', '# while True:\\n', 'while page_number <= max_pages:\\n', '   url = f\"https://www.avito.ma/fr/maroc/voitures_d_occasion-à_vendre?price={prix_min}&o={page_number}\"\\n', '   print(f\"\\\\nPage-{page_number}\", end=\\' \\')\\n', '   page_number += 1\\n', '   response = requests.get(url, headers=headers)\\n', \"   soupe = BeautifulSoup(response.text, 'html.parser')\\n\", \"   cars = soupe.select('a.sc-1jge648-0.jZXrfL')\\n\", \"   links = [car.get('href') for car in cars]\\n\", '\\n', '   if (len(links) == 0):\\n', '      break\\n', '\\n', '   for i, link in enumerate(links):\\n', '      # print(f\"{i}\", end=\\' \\')\\n', '      reponse_voiture = requests.get(link, headers=headers)\\n', \"      soup = BeautifulSoup(reponse_voiture.text, 'html.parser')\\n\", \"      titre = soup.find('h1').text.strip() if soup.find('h1') else ''\\n\", '      localisation = soup.select_one(\\n', \"          'span.sc-1x0vz2r-0').text.strip() if soup.select_one('span.sc-1x0vz2r-0') else ''\\n\", \"      prix = soup.select_one('p.sc-1x0vz2r-0.lnEFFR.sc-1veij0r-10.jdRkSM').text.strip(\\n\", \"      ) if soup.select_one('p.sc-1x0vz2r-0.lnEFFR.sc-1veij0r-10.jdRkSM') else ''\\n\", '\\n', \"      car_details = soup.select('div.sc-19cngu6-1.doRGIC')\\n\", '      car = {\\n', \"          'Titre': titre,\\n\", \"          'Localisation': localisation,\\n\", \"          'Prix': prix,\\n\", \"          'Année-Modèle': '',\\n\", \"          'Boite de vitesses': '',\\n\", \"          'Type de carburant': '',\\n\", \"          'Kilométrage': '',\\n\", \"          'Marque': '',\\n\", \"          'Modèle': '',\\n\", \"          'Nombre de portes': '',\\n\", \"          'Origine': '',\\n\", \"          'Première main': '',\\n\", \"          'Puissance fiscale': '',\\n\", \"          'État': ''\\n\", '      }\\n', '\\n', '      # les détails de la voitures\\n', '      for detail in car_details:\\n', \"         label = detail.select_one('span.sc-1x0vz2r-0.bXFCIH')\\n\", \"         value = detail.select_one('span.sc-1x0vz2r-0.fjZBup')\\n\", '         if label and value:\\n', '            key = label.text.strip()\\n', '            value = value.text.strip()\\n', '            car[key] = value\\n', '\\n', '      # Initialiser tous les équipements à False\\n', '      for eq in equipements_possibles:\\n', '         car[eq] = False\\n', '\\n', \"      # Sélectionner tous les icônes d'équipements\\n\", \"      equip_icons = soup.select('div.sc-19cngu6-1.doRGIC img')\\n\", '      for icon in equip_icons:\\n', \"         alt_text = icon.get('alt', '').strip()\\n\", '         if alt_text in equipements_possibles:\\n', '            car[alt_text] = True\\n', '      data.append(car)\\n', '\\n', '\\n', 'df = pd.DataFrame(data, columns=car.keys())\\n', '\\n', 'timestamp = datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")\\n', 'df.to_csv(\\n', '    f\"{data_base_path}/data_avito_{start_page}_to_{end_page}_pages_{timestamp}.csv\", index=False)']\n",
      "Found start_page in line: start_page = 1\n",
      "\n",
      "Found end_page in line: end_page = 500\n",
      "\n",
      "Created notebook: scraping_notebooks/data_avito_notebook_501_to_1000.ipynb\n",
      "Generating notebook for: scraping_notebooks/data_avito_page_1001_to_1500.csv\n",
      "Inspecting code cell: ['import pandas as pd\\n', 'import requests\\n', 'from bs4 import BeautifulSoup\\n', 'from datetime import datetime\\n', 'import os\\n', '\\n', \"data_base_path = '../scraped_data'\\n\", 'os.makedirs(data_base_path, exist_ok=True)\\n', '\\n', 'data = []\\n', 'start_page = 501\\n', 'end_page = 1000\\n', '\\n', 'page_number = start_page\\n', 'max_pages = end_page\\n', '\\n', 'prix_min = 1\\n', '\\n', 'headers = {\\n', \"    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\\n\", \"    'Accept-Language': 'en-US,en;q=0.9',\\n\", '}\\n', '\\n', 'equipements_possibles = [\\n', \"    'ABS',\\n\", \"    'Airbags',\\n\", \"    'CD/MP3/Bluetooth',\\n\", \"    'Caméra de recul',\\n\", \"    'Climatisation',\\n\", \"    'ESP',\\n\", \"    'Jantes aluminium',\\n\", \"    'Limiteur de vitesse',\\n\", \"    'Ordinateur de bord',\\n\", \"    'Radar de recul',\\n\", \"    'Régulateur de vitesse',\\n\", \"    'Sièges cuir',\\n\", \"    'Système de navigation/GPS',\\n\", \"    'Toit ouvrant',\\n\", \"    'Verrouillage centralisé à distance',\\n\", \"    'Vitres électriques'\\n\", ']\\n', '\\n', '# while True:\\n', 'while page_number <= max_pages:\\n', '   url = f\"https://www.avito.ma/fr/maroc/voitures_d_occasion-à_vendre?price={prix_min}&o={page_number}\"\\n', '   print(f\"\\\\nPage-{page_number}\", end=\\' \\')\\n', '   page_number += 1\\n', '   response = requests.get(url, headers=headers)\\n', \"   soupe = BeautifulSoup(response.text, 'html.parser')\\n\", \"   cars = soupe.select('a.sc-1jge648-0.jZXrfL')\\n\", \"   links = [car.get('href') for car in cars]\\n\", '\\n', '   if (len(links) == 0):\\n', '      break\\n', '\\n', '   for i, link in enumerate(links):\\n', '      # print(f\"{i}\", end=\\' \\')\\n', '      reponse_voiture = requests.get(link, headers=headers)\\n', \"      soup = BeautifulSoup(reponse_voiture.text, 'html.parser')\\n\", \"      titre = soup.find('h1').text.strip() if soup.find('h1') else ''\\n\", '      localisation = soup.select_one(\\n', \"          'span.sc-1x0vz2r-0').text.strip() if soup.select_one('span.sc-1x0vz2r-0') else ''\\n\", \"      prix = soup.select_one('p.sc-1x0vz2r-0.lnEFFR.sc-1veij0r-10.jdRkSM').text.strip(\\n\", \"      ) if soup.select_one('p.sc-1x0vz2r-0.lnEFFR.sc-1veij0r-10.jdRkSM') else ''\\n\", '\\n', \"      car_details = soup.select('div.sc-19cngu6-1.doRGIC')\\n\", '      car = {\\n', \"          'Titre': titre,\\n\", \"          'Localisation': localisation,\\n\", \"          'Prix': prix,\\n\", \"          'Année-Modèle': '',\\n\", \"          'Boite de vitesses': '',\\n\", \"          'Type de carburant': '',\\n\", \"          'Kilométrage': '',\\n\", \"          'Marque': '',\\n\", \"          'Modèle': '',\\n\", \"          'Nombre de portes': '',\\n\", \"          'Origine': '',\\n\", \"          'Première main': '',\\n\", \"          'Puissance fiscale': '',\\n\", \"          'État': ''\\n\", '      }\\n', '\\n', '      # les détails de la voitures\\n', '      for detail in car_details:\\n', \"         label = detail.select_one('span.sc-1x0vz2r-0.bXFCIH')\\n\", \"         value = detail.select_one('span.sc-1x0vz2r-0.fjZBup')\\n\", '         if label and value:\\n', '            key = label.text.strip()\\n', '            value = value.text.strip()\\n', '            car[key] = value\\n', '\\n', '      # Initialiser tous les équipements à False\\n', '      for eq in equipements_possibles:\\n', '         car[eq] = False\\n', '\\n', \"      # Sélectionner tous les icônes d'équipements\\n\", \"      equip_icons = soup.select('div.sc-19cngu6-1.doRGIC img')\\n\", '      for icon in equip_icons:\\n', \"         alt_text = icon.get('alt', '').strip()\\n\", '         if alt_text in equipements_possibles:\\n', '            car[alt_text] = True\\n', '      data.append(car)\\n', '\\n', '\\n', 'df = pd.DataFrame(data, columns=car.keys())\\n', '\\n', 'timestamp = datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")\\n', 'df.to_csv(\\n', '    f\"{data_base_path}/data_avito_{start_page}_to_{end_page}_pages_{timestamp}.csv\", index=False)']\n",
      "Found start_page in line: start_page = 501\n",
      "\n",
      "Found end_page in line: end_page = 1000\n",
      "\n",
      "Created notebook: scraping_notebooks/data_avito_notebook_1001_to_1500.ipynb\n",
      "Generating notebook for: scraping_notebooks/data_avito_page_1501_to_1933.csv\n",
      "Inspecting code cell: ['import pandas as pd\\n', 'import requests\\n', 'from bs4 import BeautifulSoup\\n', 'from datetime import datetime\\n', 'import os\\n', '\\n', \"data_base_path = '../scraped_data'\\n\", 'os.makedirs(data_base_path, exist_ok=True)\\n', '\\n', 'data = []\\n', 'start_page = 1001\\n', 'end_page = 1500\\n', '\\n', 'page_number = start_page\\n', 'max_pages = end_page\\n', '\\n', 'prix_min = 1\\n', '\\n', 'headers = {\\n', \"    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\\n\", \"    'Accept-Language': 'en-US,en;q=0.9',\\n\", '}\\n', '\\n', 'equipements_possibles = [\\n', \"    'ABS',\\n\", \"    'Airbags',\\n\", \"    'CD/MP3/Bluetooth',\\n\", \"    'Caméra de recul',\\n\", \"    'Climatisation',\\n\", \"    'ESP',\\n\", \"    'Jantes aluminium',\\n\", \"    'Limiteur de vitesse',\\n\", \"    'Ordinateur de bord',\\n\", \"    'Radar de recul',\\n\", \"    'Régulateur de vitesse',\\n\", \"    'Sièges cuir',\\n\", \"    'Système de navigation/GPS',\\n\", \"    'Toit ouvrant',\\n\", \"    'Verrouillage centralisé à distance',\\n\", \"    'Vitres électriques'\\n\", ']\\n', '\\n', '# while True:\\n', 'while page_number <= max_pages:\\n', '   url = f\"https://www.avito.ma/fr/maroc/voitures_d_occasion-à_vendre?price={prix_min}&o={page_number}\"\\n', '   print(f\"\\\\nPage-{page_number}\", end=\\' \\')\\n', '   page_number += 1\\n', '   response = requests.get(url, headers=headers)\\n', \"   soupe = BeautifulSoup(response.text, 'html.parser')\\n\", \"   cars = soupe.select('a.sc-1jge648-0.jZXrfL')\\n\", \"   links = [car.get('href') for car in cars]\\n\", '\\n', '   if (len(links) == 0):\\n', '      break\\n', '\\n', '   for i, link in enumerate(links):\\n', '      # print(f\"{i}\", end=\\' \\')\\n', '      reponse_voiture = requests.get(link, headers=headers)\\n', \"      soup = BeautifulSoup(reponse_voiture.text, 'html.parser')\\n\", \"      titre = soup.find('h1').text.strip() if soup.find('h1') else ''\\n\", '      localisation = soup.select_one(\\n', \"          'span.sc-1x0vz2r-0').text.strip() if soup.select_one('span.sc-1x0vz2r-0') else ''\\n\", \"      prix = soup.select_one('p.sc-1x0vz2r-0.lnEFFR.sc-1veij0r-10.jdRkSM').text.strip(\\n\", \"      ) if soup.select_one('p.sc-1x0vz2r-0.lnEFFR.sc-1veij0r-10.jdRkSM') else ''\\n\", '\\n', \"      car_details = soup.select('div.sc-19cngu6-1.doRGIC')\\n\", '      car = {\\n', \"          'Titre': titre,\\n\", \"          'Localisation': localisation,\\n\", \"          'Prix': prix,\\n\", \"          'Année-Modèle': '',\\n\", \"          'Boite de vitesses': '',\\n\", \"          'Type de carburant': '',\\n\", \"          'Kilométrage': '',\\n\", \"          'Marque': '',\\n\", \"          'Modèle': '',\\n\", \"          'Nombre de portes': '',\\n\", \"          'Origine': '',\\n\", \"          'Première main': '',\\n\", \"          'Puissance fiscale': '',\\n\", \"          'État': ''\\n\", '      }\\n', '\\n', '      # les détails de la voitures\\n', '      for detail in car_details:\\n', \"         label = detail.select_one('span.sc-1x0vz2r-0.bXFCIH')\\n\", \"         value = detail.select_one('span.sc-1x0vz2r-0.fjZBup')\\n\", '         if label and value:\\n', '            key = label.text.strip()\\n', '            value = value.text.strip()\\n', '            car[key] = value\\n', '\\n', '      # Initialiser tous les équipements à False\\n', '      for eq in equipements_possibles:\\n', '         car[eq] = False\\n', '\\n', \"      # Sélectionner tous les icônes d'équipements\\n\", \"      equip_icons = soup.select('div.sc-19cngu6-1.doRGIC img')\\n\", '      for icon in equip_icons:\\n', \"         alt_text = icon.get('alt', '').strip()\\n\", '         if alt_text in equipements_possibles:\\n', '            car[alt_text] = True\\n', '      data.append(car)\\n', '\\n', '\\n', 'df = pd.DataFrame(data, columns=car.keys())\\n', '\\n', 'timestamp = datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")\\n', 'df.to_csv(\\n', '    f\"{data_base_path}/data_avito_{start_page}_to_{end_page}_pages_{timestamp}.csv\", index=False)']\n",
      "Found start_page in line: start_page = 1001\n",
      "\n",
      "Found end_page in line: end_page = 1500\n",
      "\n",
      "Created notebook: scraping_notebooks/data_avito_notebook_1501_to_1933.ipynb\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Parameters\n",
    "last_page = 1933\n",
    "base_path = 'scraping_notebooks'\n",
    "step = 500\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# Read the base notebook with UTF-8 encoding\n",
    "try:\n",
    "    with open('./base.ipynb', 'r', encoding='utf-8') as f:\n",
    "        notebook_content = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: base.ipynb not found\")\n",
    "    exit(1)\n",
    "\n",
    "# Iterate over page ranges\n",
    "for i in range(0, last_page, step):\n",
    "    # Define the output path for the CSV (for reference)\n",
    "    csv_path = f\"{base_path}/data_avito_page_{i+1}_to_{min(i+step, last_page)}.csv\"\n",
    "    print(f\"Generating notebook for: {csv_path}\")\n",
    "\n",
    "    # Create a copy of the notebook content\n",
    "    new_notebook = notebook_content.copy()\n",
    "\n",
    "    # Modify the notebook cells\n",
    "    for cell in new_notebook['cells']:\n",
    "        if cell['cell_type'] == 'code':\n",
    "            # Debug: Print the cell content to inspect\n",
    "            print(f\"Inspecting code cell: {cell['source']}\")\n",
    "            for j, line in enumerate(cell['source']):\n",
    "                # Use more flexible matching for start_page and end_page\n",
    "                if line.strip().startswith('start_page'):\n",
    "                    print(f\"Found start_page in line: {line}\")\n",
    "                    cell['source'][j] = f'start_page = {i+1}\\n'\n",
    "                elif line.strip().startswith('end_page'):\n",
    "                    print(f\"Found end_page in line: {line}\")\n",
    "                    cell['source'][j] = f'end_page = {min(i+step, last_page)}\\n'\n",
    "\n",
    "    # Define the new notebook filename\n",
    "    notebook_path = f\"{base_path}/data_avito_notebook_{i+1}_to_{min(i+step, last_page)}.ipynb\"\n",
    "\n",
    "    # Save the modified notebook with UTF-8 encoding\n",
    "    with open(notebook_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(new_notebook, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Created notebook: {notebook_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
